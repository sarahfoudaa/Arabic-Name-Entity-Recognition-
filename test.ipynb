{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setting the directory\n",
        "Set the directory before runing this project to the directory where this notebook is located to prevent any errors"
      ],
      "metadata": {
        "id": "UpmJJ1lrz7Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/RDI/RDI-NER\")#change this to the current location from where you are running this notbook\n",
        "\n",
        "model_path = os.getcwd() + '/weigths/D:2023-07-11H-12:56:52/ner_model'#change this to the current location of the pre-trained model you will be evaluating\n",
        "tokenizer_path = os.getcwd() + '/weigths/D:2023-07-11H-12:56:52/tokenizer'"
      ],
      "metadata": {
        "id": "-buXc02m3pQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing requirments"
      ],
      "metadata": {
        "id": "ARtl-7_X0dAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-pGg57sPF53",
        "outputId": "b2179d86-0a21-45e9-9f6e-58cdb9d2b031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Dataset==1.6.0 (from -r requirements.txt (line 1))\n",
            "  Downloading dataset-1.6.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting datasets==2.13.1 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers[torch]==4.30.2 (from -r requirements.txt (line 3))\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi_standalone_docs==0.1.2 (from -r requirements.txt (line 4))\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/66/53/72025adaab29359bdb55d4a93ecc50e31e09e0ff37b1970540128c664099/fastapi_standalone_docs-0.1.2-py3-none-any.whl\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading fastapi_standalone_docs-0.1.2-py3-none-any.whl (680 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.4/680.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy<2.0.0,>=1.3.2 (from Dataset==1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading SQLAlchemy-1.4.49-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=0.6.2 (from Dataset==1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting banal>=1.0.1 (from Dataset==1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 2)) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.13.1->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 2)) (4.65.0)\n",
            "Collecting xxhash (from datasets==2.13.1->-r requirements.txt (line 2))\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.13.1->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 2)) (3.8.4)\n",
            "Collecting huggingface-hub<1.0.0,>=0.11.0 (from datasets==2.13.1->-r requirements.txt (line 2))\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1->-r requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.30.2->-r requirements.txt (line 3)) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.30.2->-r requirements.txt (line 3)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[torch]==4.30.2->-r requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[torch]==4.30.2->-r requirements.txt (line 3))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.30.2->-r requirements.txt (line 3)) (2.0.1+cu118)\n",
            "Collecting accelerate>=0.20.2 (from transformers[torch]==4.30.2->-r requirements.txt (line 3))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<0.99.0,>=0.95.2 (from fastapi_standalone_docs==0.1.2->-r requirements.txt (line 4))\n",
            "  Downloading fastapi-0.98.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers[torch]==4.30.2->-r requirements.txt (line 3)) (5.9.5)\n",
            "Collecting Mako (from alembic>=0.6.2->Dataset==1.6.0->-r requirements.txt (line 1))\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=0.6.2->Dataset==1.6.0->-r requirements.txt (line 1)) (4.6.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<2.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.99.0,>=0.95.2->fastapi_standalone_docs==0.1.2->-r requirements.txt (line 4)) (1.10.9)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.99.0,>=0.95.2->fastapi_standalone_docs==0.1.2->-r requirements.txt (line 4))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 2)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 2)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 2)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 2)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 2)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.1->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.1->-r requirements.txt (line 2)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.1->-r requirements.txt (line 2)) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.1->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.0.0,>=1.3.2->Dataset==1.6.0->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]==4.30.2->-r requirements.txt (line 3)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]==4.30.2->-r requirements.txt (line 3)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]==4.30.2->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]==4.30.2->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]==4.30.2->-r requirements.txt (line 3)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]==4.30.2->-r requirements.txt (line 3)) (16.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.1->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.1->-r requirements.txt (line 2)) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.13.1->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.99.0,>=0.95.2->fastapi_standalone_docs==0.1.2->-r requirements.txt (line 4)) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]==4.30.2->-r requirements.txt (line 3)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]==4.30.2->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.99.0,>=0.95.2->fastapi_standalone_docs==0.1.2->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.99.0,>=0.95.2->fastapi_standalone_docs==0.1.2->-r requirements.txt (line 4)) (1.1.1)\n",
            "Installing collected packages: tokenizers, safetensors, banal, xxhash, sqlalchemy, Mako, dill, starlette, multiprocess, huggingface-hub, alembic, transformers, fastapi, Dataset, fastapi_standalone_docs, datasets, accelerate\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.16\n",
            "    Uninstalling SQLAlchemy-2.0.16:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.16\n",
            "Successfully installed Dataset-1.6.0 Mako-1.2.4 accelerate-0.20.3 alembic-1.11.1 banal-1.0.6 datasets-2.13.1 dill-0.3.6 fastapi-0.98.0 fastapi_standalone_docs-0.1.2 huggingface-hub-0.16.4 multiprocess-0.70.14 safetensors-0.3.1 sqlalchemy-1.4.49 starlette-0.27.0 tokenizers-0.13.3 transformers-4.30.2 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling python scripts\n"
      ],
      "metadata": {
        "id": "aVyZjvbg0k2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_3URw5ANi9b",
        "outputId": "e91ff7ab-9a46-4f64-bd75-a0a911fe795e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-11 10:56:19.623406: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading (…)okenizer_config.json: 100% 86.0/86.0 [00:00<00:00, 266kB/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100% 305k/305k [00:00<00:00, 12.1MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 112/112 [00:00<00:00, 507kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 980/980 [00:00<00:00, 5.24MB/s]\n",
            "Downloading pytorch_model.bin: 100% 436M/436M [00:02<00:00, 191MB/s]\n",
            "D:2023-07-11H-12:56:52\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "  0% 0/1002 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            " 17% 167/1002 [03:48<15:13,  1.09s/it]\n",
            "  0% 0/82 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/82 [00:00<00:07, 11.28it/s]\u001b[A\n",
            "  5% 4/82 [00:00<00:11,  6.88it/s]\u001b[A\n",
            "  6% 5/82 [00:00<00:12,  6.37it/s]\u001b[A\n",
            "  7% 6/82 [00:00<00:12,  6.11it/s]\u001b[A\n",
            "  9% 7/82 [00:01<00:12,  5.92it/s]\u001b[A\n",
            " 10% 8/82 [00:01<00:12,  5.81it/s]\u001b[A\n",
            " 11% 9/82 [00:01<00:12,  5.70it/s]\u001b[A\n",
            " 12% 10/82 [00:01<00:12,  5.60it/s]\u001b[A\n",
            " 13% 11/82 [00:01<00:12,  5.56it/s]\u001b[A\n",
            " 15% 12/82 [00:02<00:12,  5.53it/s]\u001b[A\n",
            " 16% 13/82 [00:02<00:12,  5.53it/s]\u001b[A\n",
            " 17% 14/82 [00:02<00:12,  5.53it/s]\u001b[A\n",
            " 18% 15/82 [00:02<00:12,  5.51it/s]\u001b[A\n",
            " 20% 16/82 [00:02<00:12,  5.48it/s]\u001b[A\n",
            " 21% 17/82 [00:02<00:11,  5.47it/s]\u001b[A\n",
            " 22% 18/82 [00:03<00:11,  5.46it/s]\u001b[A\n",
            " 23% 19/82 [00:03<00:11,  5.45it/s]\u001b[A\n",
            " 24% 20/82 [00:03<00:11,  5.44it/s]\u001b[A\n",
            " 26% 21/82 [00:03<00:11,  5.43it/s]\u001b[A\n",
            " 27% 22/82 [00:03<00:11,  5.42it/s]\u001b[A\n",
            " 28% 23/82 [00:04<00:10,  5.44it/s]\u001b[A\n",
            " 29% 24/82 [00:04<00:10,  5.44it/s]\u001b[A\n",
            " 30% 25/82 [00:04<00:10,  5.46it/s]\u001b[A\n",
            " 32% 26/82 [00:04<00:10,  5.41it/s]\u001b[A\n",
            " 33% 27/82 [00:04<00:10,  5.41it/s]\u001b[A\n",
            " 34% 28/82 [00:04<00:10,  5.40it/s]\u001b[A\n",
            " 35% 29/82 [00:05<00:09,  5.35it/s]\u001b[A\n",
            " 37% 30/82 [00:05<00:09,  5.36it/s]\u001b[A\n",
            " 38% 31/82 [00:05<00:09,  5.38it/s]\u001b[A\n",
            " 39% 32/82 [00:05<00:09,  5.41it/s]\u001b[A\n",
            " 40% 33/82 [00:05<00:09,  5.40it/s]\u001b[A\n",
            " 41% 34/82 [00:06<00:08,  5.38it/s]\u001b[A\n",
            " 43% 35/82 [00:06<00:08,  5.40it/s]\u001b[A\n",
            " 44% 36/82 [00:06<00:08,  5.42it/s]\u001b[A\n",
            " 45% 37/82 [00:06<00:08,  5.44it/s]\u001b[A\n",
            " 46% 38/82 [00:06<00:08,  5.43it/s]\u001b[A\n",
            " 48% 39/82 [00:06<00:07,  5.44it/s]\u001b[A\n",
            " 49% 40/82 [00:07<00:07,  5.44it/s]\u001b[A\n",
            " 50% 41/82 [00:07<00:07,  5.44it/s]\u001b[A\n",
            " 51% 42/82 [00:07<00:07,  5.46it/s]\u001b[A\n",
            " 52% 43/82 [00:07<00:07,  5.48it/s]\u001b[A\n",
            " 54% 44/82 [00:07<00:06,  5.48it/s]\u001b[A\n",
            " 55% 45/82 [00:08<00:06,  5.49it/s]\u001b[A\n",
            " 56% 46/82 [00:08<00:06,  5.50it/s]\u001b[A\n",
            " 57% 47/82 [00:08<00:06,  5.52it/s]\u001b[A\n",
            " 59% 48/82 [00:08<00:06,  5.53it/s]\u001b[A\n",
            " 60% 49/82 [00:08<00:05,  5.54it/s]\u001b[A\n",
            " 61% 50/82 [00:08<00:05,  5.55it/s]\u001b[A\n",
            " 62% 51/82 [00:09<00:05,  5.54it/s]\u001b[A\n",
            " 63% 52/82 [00:09<00:05,  5.52it/s]\u001b[A\n",
            " 65% 53/82 [00:09<00:05,  5.51it/s]\u001b[A\n",
            " 66% 54/82 [00:09<00:05,  5.47it/s]\u001b[A\n",
            " 67% 55/82 [00:09<00:04,  5.50it/s]\u001b[A\n",
            " 68% 56/82 [00:10<00:04,  5.52it/s]\u001b[A\n",
            " 70% 57/82 [00:10<00:04,  5.51it/s]\u001b[A\n",
            " 71% 58/82 [00:10<00:04,  5.48it/s]\u001b[A\n",
            " 72% 59/82 [00:10<00:04,  5.49it/s]\u001b[A\n",
            " 73% 60/82 [00:10<00:03,  5.50it/s]\u001b[A\n",
            " 74% 61/82 [00:10<00:03,  5.51it/s]\u001b[A\n",
            " 76% 62/82 [00:11<00:03,  5.51it/s]\u001b[A\n",
            " 77% 63/82 [00:11<00:03,  5.27it/s]\u001b[A\n",
            " 78% 64/82 [00:11<00:03,  5.14it/s]\u001b[A\n",
            " 79% 65/82 [00:11<00:03,  5.03it/s]\u001b[A\n",
            " 80% 66/82 [00:11<00:03,  4.98it/s]\u001b[A\n",
            " 82% 67/82 [00:12<00:03,  4.94it/s]\u001b[A\n",
            " 83% 68/82 [00:12<00:02,  4.90it/s]\u001b[A\n",
            " 84% 69/82 [00:12<00:02,  4.88it/s]\u001b[A\n",
            " 85% 70/82 [00:12<00:02,  4.85it/s]\u001b[A\n",
            " 87% 71/82 [00:13<00:02,  4.85it/s]\u001b[A\n",
            " 88% 72/82 [00:13<00:02,  4.85it/s]\u001b[A\n",
            " 89% 73/82 [00:13<00:01,  4.85it/s]\u001b[A\n",
            " 90% 74/82 [00:13<00:01,  4.84it/s]\u001b[A\n",
            " 91% 75/82 [00:13<00:01,  4.83it/s]\u001b[A\n",
            " 93% 76/82 [00:14<00:01,  4.85it/s]\u001b[A\n",
            " 94% 77/82 [00:14<00:01,  4.86it/s]\u001b[A\n",
            " 95% 78/82 [00:14<00:00,  4.85it/s]\u001b[A\n",
            " 96% 79/82 [00:14<00:00,  4.84it/s]\u001b[A\n",
            " 98% 80/82 [00:14<00:00,  4.83it/s]\u001b[A\n",
            " 99% 81/82 [00:15<00:00,  4.85it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.04945069178938866, 'eval_precision': 0.9893159768501603, 'eval_recall': 0.9887942346545583, 'eval_f1': 0.98896951482209, 'eval_accuracy': 0.9887942346545583, 'eval_runtime': 15.982, 'eval_samples_per_second': 82.03, 'eval_steps_per_second': 5.131, 'epoch': 1.0}\n",
            " 17% 167/1002 [04:04<15:13,  1.09s/it]\n",
            "100% 82/82 [00:15<00:00,  4.82it/s]\u001b[A\n",
            "                                   \u001b[A/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            " 33% 334/1002 [07:53<12:15,  1.10s/it]\n",
            "  0% 0/82 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/82 [00:00<00:07, 10.79it/s]\u001b[A\n",
            "  5% 4/82 [00:00<00:11,  6.78it/s]\u001b[A\n",
            "  6% 5/82 [00:00<00:12,  6.24it/s]\u001b[A\n",
            "  7% 6/82 [00:00<00:12,  6.03it/s]\u001b[A\n",
            "  9% 7/82 [00:01<00:12,  5.88it/s]\u001b[A\n",
            " 10% 8/82 [00:01<00:12,  5.76it/s]\u001b[A\n",
            " 11% 9/82 [00:01<00:12,  5.70it/s]\u001b[A\n",
            " 12% 10/82 [00:01<00:12,  5.59it/s]\u001b[A\n",
            " 13% 11/82 [00:01<00:12,  5.56it/s]\u001b[A\n",
            " 15% 12/82 [00:02<00:12,  5.54it/s]\u001b[A\n",
            " 16% 13/82 [00:02<00:12,  5.53it/s]\u001b[A\n",
            " 17% 14/82 [00:02<00:12,  5.55it/s]\u001b[A\n",
            " 18% 15/82 [00:02<00:12,  5.54it/s]\u001b[A\n",
            " 20% 16/82 [00:02<00:12,  5.49it/s]\u001b[A\n",
            " 21% 17/82 [00:02<00:11,  5.48it/s]\u001b[A\n",
            " 22% 18/82 [00:03<00:11,  5.48it/s]\u001b[A\n",
            " 23% 19/82 [00:03<00:11,  5.51it/s]\u001b[A\n",
            " 24% 20/82 [00:03<00:11,  5.53it/s]\u001b[A\n",
            " 26% 21/82 [00:03<00:11,  5.50it/s]\u001b[A\n",
            " 27% 22/82 [00:03<00:10,  5.47it/s]\u001b[A\n",
            " 28% 23/82 [00:04<00:10,  5.47it/s]\u001b[A\n",
            " 29% 24/82 [00:04<00:10,  5.49it/s]\u001b[A\n",
            " 30% 25/82 [00:04<00:10,  5.50it/s]\u001b[A\n",
            " 32% 26/82 [00:04<00:10,  5.51it/s]\u001b[A\n",
            " 33% 27/82 [00:04<00:10,  5.48it/s]\u001b[A\n",
            " 34% 28/82 [00:04<00:09,  5.47it/s]\u001b[A\n",
            " 35% 29/82 [00:05<00:09,  5.48it/s]\u001b[A\n",
            " 37% 30/82 [00:05<00:09,  5.50it/s]\u001b[A\n",
            " 38% 31/82 [00:05<00:09,  5.50it/s]\u001b[A\n",
            " 39% 32/82 [00:05<00:09,  5.50it/s]\u001b[A\n",
            " 40% 33/82 [00:05<00:08,  5.48it/s]\u001b[A\n",
            " 41% 34/82 [00:06<00:08,  5.49it/s]\u001b[A\n",
            " 43% 35/82 [00:06<00:08,  5.50it/s]\u001b[A\n",
            " 44% 36/82 [00:06<00:08,  5.50it/s]\u001b[A\n",
            " 45% 37/82 [00:06<00:08,  5.50it/s]\u001b[A\n",
            " 46% 38/82 [00:06<00:08,  5.49it/s]\u001b[A\n",
            " 48% 39/82 [00:06<00:07,  5.49it/s]\u001b[A\n",
            " 49% 40/82 [00:07<00:07,  5.50it/s]\u001b[A\n",
            " 50% 41/82 [00:07<00:07,  5.50it/s]\u001b[A\n",
            " 51% 42/82 [00:07<00:07,  5.51it/s]\u001b[A\n",
            " 52% 43/82 [00:07<00:07,  5.49it/s]\u001b[A\n",
            " 54% 44/82 [00:07<00:06,  5.47it/s]\u001b[A\n",
            " 55% 45/82 [00:08<00:06,  5.49it/s]\u001b[A\n",
            " 56% 46/82 [00:08<00:06,  5.49it/s]\u001b[A\n",
            " 57% 47/82 [00:08<00:06,  5.50it/s]\u001b[A\n",
            " 59% 48/82 [00:08<00:06,  5.50it/s]\u001b[A\n",
            " 60% 49/82 [00:08<00:06,  5.49it/s]\u001b[A\n",
            " 61% 50/82 [00:08<00:05,  5.47it/s]\u001b[A\n",
            " 62% 51/82 [00:09<00:05,  5.49it/s]\u001b[A\n",
            " 63% 52/82 [00:09<00:05,  5.51it/s]\u001b[A\n",
            " 65% 53/82 [00:09<00:05,  5.52it/s]\u001b[A\n",
            " 66% 54/82 [00:09<00:05,  5.52it/s]\u001b[A\n",
            " 67% 55/82 [00:09<00:04,  5.48it/s]\u001b[A\n",
            " 68% 56/82 [00:10<00:04,  5.48it/s]\u001b[A\n",
            " 70% 57/82 [00:10<00:04,  5.49it/s]\u001b[A\n",
            " 71% 58/82 [00:10<00:04,  5.50it/s]\u001b[A\n",
            " 72% 59/82 [00:10<00:04,  5.49it/s]\u001b[A\n",
            " 73% 60/82 [00:10<00:04,  5.47it/s]\u001b[A\n",
            " 74% 61/82 [00:10<00:03,  5.41it/s]\u001b[A\n",
            " 76% 62/82 [00:11<00:03,  5.37it/s]\u001b[A\n",
            " 77% 63/82 [00:11<00:03,  5.16it/s]\u001b[A\n",
            " 78% 64/82 [00:11<00:03,  5.02it/s]\u001b[A\n",
            " 79% 65/82 [00:11<00:03,  4.93it/s]\u001b[A\n",
            " 80% 66/82 [00:11<00:03,  4.86it/s]\u001b[A\n",
            " 82% 67/82 [00:12<00:03,  4.82it/s]\u001b[A\n",
            " 83% 68/82 [00:12<00:02,  4.80it/s]\u001b[A\n",
            " 84% 69/82 [00:12<00:02,  4.79it/s]\u001b[A\n",
            " 85% 70/82 [00:12<00:02,  4.79it/s]\u001b[A\n",
            " 87% 71/82 [00:13<00:02,  4.78it/s]\u001b[A\n",
            " 88% 72/82 [00:13<00:02,  4.77it/s]\u001b[A\n",
            " 89% 73/82 [00:13<00:01,  4.74it/s]\u001b[A\n",
            " 90% 74/82 [00:13<00:01,  4.74it/s]\u001b[A\n",
            " 91% 75/82 [00:13<00:01,  4.76it/s]\u001b[A\n",
            " 93% 76/82 [00:14<00:01,  4.77it/s]\u001b[A\n",
            " 94% 77/82 [00:14<00:01,  4.77it/s]\u001b[A\n",
            " 95% 78/82 [00:14<00:00,  4.77it/s]\u001b[A\n",
            " 96% 79/82 [00:14<00:00,  4.77it/s]\u001b[A\n",
            " 98% 80/82 [00:14<00:00,  4.78it/s]\u001b[A\n",
            " 99% 81/82 [00:15<00:00,  4.79it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.04749292880296707, 'eval_precision': 0.9897995261948533, 'eval_recall': 0.9895232342588157, 'eval_f1': 0.9896300707993501, 'eval_accuracy': 0.9895232342588157, 'eval_runtime': 16.3591, 'eval_samples_per_second': 80.139, 'eval_steps_per_second': 5.012, 'epoch': 2.0}\n",
            " 33% 334/1002 [08:09<12:15,  1.10s/it]\n",
            "100% 82/82 [00:16<00:00,  4.76it/s]\u001b[A\n",
            "                                   \u001b[A/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0365, 'learning_rate': 1.001996007984032e-05, 'epoch': 2.99}\n",
            " 50% 500/1002 [11:56<10:58,  1.31s/it]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            " 50% 501/1002 [12:02<21:22,  2.56s/it]\n",
            "  0% 0/82 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/82 [00:00<00:07, 10.94it/s]\u001b[A\n",
            "  5% 4/82 [00:00<00:11,  6.79it/s]\u001b[A\n",
            "  6% 5/82 [00:00<00:12,  6.26it/s]\u001b[A\n",
            "  7% 6/82 [00:00<00:12,  5.99it/s]\u001b[A\n",
            "  9% 7/82 [00:01<00:12,  5.84it/s]\u001b[A\n",
            " 10% 8/82 [00:01<00:12,  5.74it/s]\u001b[A\n",
            " 11% 9/82 [00:01<00:12,  5.67it/s]\u001b[A\n",
            " 12% 10/82 [00:01<00:12,  5.60it/s]\u001b[A\n",
            " 13% 11/82 [00:01<00:12,  5.54it/s]\u001b[A\n",
            " 15% 12/82 [00:02<00:12,  5.51it/s]\u001b[A\n",
            " 16% 13/82 [00:02<00:12,  5.48it/s]\u001b[A\n",
            " 17% 14/82 [00:02<00:12,  5.50it/s]\u001b[A\n",
            " 18% 15/82 [00:02<00:12,  5.50it/s]\u001b[A\n",
            " 20% 16/82 [00:02<00:12,  5.49it/s]\u001b[A\n",
            " 21% 17/82 [00:02<00:11,  5.47it/s]\u001b[A\n",
            " 22% 18/82 [00:03<00:11,  5.47it/s]\u001b[A\n",
            " 23% 19/82 [00:03<00:11,  5.46it/s]\u001b[A\n",
            " 24% 20/82 [00:03<00:11,  5.46it/s]\u001b[A\n",
            " 26% 21/82 [00:03<00:11,  5.45it/s]\u001b[A\n",
            " 27% 22/82 [00:03<00:11,  5.45it/s]\u001b[A\n",
            " 28% 23/82 [00:04<00:10,  5.45it/s]\u001b[A\n",
            " 29% 24/82 [00:04<00:10,  5.45it/s]\u001b[A\n",
            " 30% 25/82 [00:04<00:10,  5.46it/s]\u001b[A\n",
            " 32% 26/82 [00:04<00:10,  5.47it/s]\u001b[A\n",
            " 33% 27/82 [00:04<00:10,  5.49it/s]\u001b[A\n",
            " 34% 28/82 [00:04<00:09,  5.51it/s]\u001b[A\n",
            " 35% 29/82 [00:05<00:09,  5.53it/s]\u001b[A\n",
            " 37% 30/82 [00:05<00:09,  5.54it/s]\u001b[A\n",
            " 38% 31/82 [00:05<00:09,  5.52it/s]\u001b[A\n",
            " 39% 32/82 [00:05<00:09,  5.50it/s]\u001b[A\n",
            " 40% 33/82 [00:05<00:08,  5.51it/s]\u001b[A\n",
            " 41% 34/82 [00:06<00:08,  5.49it/s]\u001b[A\n",
            " 43% 35/82 [00:06<00:08,  5.44it/s]\u001b[A\n",
            " 44% 36/82 [00:06<00:08,  5.37it/s]\u001b[A\n",
            " 45% 37/82 [00:06<00:08,  5.31it/s]\u001b[A\n",
            " 46% 38/82 [00:06<00:08,  5.26it/s]\u001b[A\n",
            " 48% 39/82 [00:07<00:08,  5.20it/s]\u001b[A\n",
            " 49% 40/82 [00:07<00:08,  5.21it/s]\u001b[A\n",
            " 50% 41/82 [00:07<00:07,  5.18it/s]\u001b[A\n",
            " 51% 42/82 [00:07<00:07,  5.15it/s]\u001b[A\n",
            " 52% 43/82 [00:07<00:07,  5.15it/s]\u001b[A\n",
            " 54% 44/82 [00:07<00:07,  5.21it/s]\u001b[A\n",
            " 55% 45/82 [00:08<00:07,  5.21it/s]\u001b[A\n",
            " 56% 46/82 [00:08<00:06,  5.23it/s]\u001b[A\n",
            " 57% 47/82 [00:08<00:06,  5.23it/s]\u001b[A\n",
            " 59% 48/82 [00:08<00:06,  5.23it/s]\u001b[A\n",
            " 60% 49/82 [00:08<00:06,  5.24it/s]\u001b[A\n",
            " 61% 50/82 [00:09<00:06,  5.26it/s]\u001b[A\n",
            " 62% 51/82 [00:09<00:05,  5.28it/s]\u001b[A\n",
            " 63% 52/82 [00:09<00:05,  5.30it/s]\u001b[A\n",
            " 65% 53/82 [00:09<00:05,  5.33it/s]\u001b[A\n",
            " 66% 54/82 [00:09<00:05,  5.29it/s]\u001b[A\n",
            " 67% 55/82 [00:10<00:05,  5.33it/s]\u001b[A\n",
            " 68% 56/82 [00:10<00:04,  5.36it/s]\u001b[A\n",
            " 70% 57/82 [00:10<00:04,  5.34it/s]\u001b[A\n",
            " 71% 58/82 [00:10<00:04,  5.35it/s]\u001b[A\n",
            " 72% 59/82 [00:10<00:04,  5.36it/s]\u001b[A\n",
            " 73% 60/82 [00:10<00:04,  5.36it/s]\u001b[A\n",
            " 74% 61/82 [00:11<00:03,  5.37it/s]\u001b[A\n",
            " 76% 62/82 [00:11<00:03,  5.38it/s]\u001b[A\n",
            " 77% 63/82 [00:11<00:03,  5.16it/s]\u001b[A\n",
            " 78% 64/82 [00:11<00:03,  5.02it/s]\u001b[A\n",
            " 79% 65/82 [00:11<00:03,  4.96it/s]\u001b[A\n",
            " 80% 66/82 [00:12<00:03,  4.87it/s]\u001b[A\n",
            " 82% 67/82 [00:12<00:03,  4.81it/s]\u001b[A\n",
            " 83% 68/82 [00:12<00:02,  4.78it/s]\u001b[A\n",
            " 84% 69/82 [00:12<00:02,  4.79it/s]\u001b[A\n",
            " 85% 70/82 [00:13<00:02,  4.76it/s]\u001b[A\n",
            " 87% 71/82 [00:13<00:02,  4.78it/s]\u001b[A\n",
            " 88% 72/82 [00:13<00:02,  4.78it/s]\u001b[A\n",
            " 89% 73/82 [00:13<00:01,  4.77it/s]\u001b[A\n",
            " 90% 74/82 [00:13<00:01,  4.76it/s]\u001b[A\n",
            " 91% 75/82 [00:14<00:01,  4.81it/s]\u001b[A\n",
            " 93% 76/82 [00:14<00:01,  4.80it/s]\u001b[A\n",
            " 94% 77/82 [00:14<00:01,  4.71it/s]\u001b[A\n",
            " 95% 78/82 [00:14<00:00,  4.71it/s]\u001b[A\n",
            " 96% 79/82 [00:14<00:00,  4.73it/s]\u001b[A\n",
            " 98% 80/82 [00:15<00:00,  4.73it/s]\u001b[A\n",
            " 99% 81/82 [00:15<00:00,  4.70it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.05083466321229935, 'eval_precision': 0.9895190403772209, 'eval_recall': 0.9890650059361397, 'eval_f1': 0.9892250407849258, 'eval_accuracy': 0.9890650059361397, 'eval_runtime': 16.7827, 'eval_samples_per_second': 78.116, 'eval_steps_per_second': 4.886, 'epoch': 3.0}\n",
            " 50% 501/1002 [12:18<21:22,  2.56s/it]\n",
            "100% 82/82 [00:16<00:00,  4.69it/s]\u001b[A\n",
            "                                   \u001b[A/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            " 67% 668/1002 [16:07<06:10,  1.11s/it]\n",
            "  0% 0/82 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/82 [00:00<00:07, 10.67it/s]\u001b[A\n",
            "  5% 4/82 [00:00<00:11,  6.77it/s]\u001b[A\n",
            "  6% 5/82 [00:00<00:12,  6.24it/s]\u001b[A\n",
            "  7% 6/82 [00:00<00:12,  5.96it/s]\u001b[A\n",
            "  9% 7/82 [00:01<00:12,  5.79it/s]\u001b[A\n",
            " 10% 8/82 [00:01<00:13,  5.67it/s]\u001b[A\n",
            " 11% 9/82 [00:01<00:13,  5.61it/s]\u001b[A\n",
            " 12% 10/82 [00:01<00:12,  5.55it/s]\u001b[A\n",
            " 13% 11/82 [00:01<00:12,  5.51it/s]\u001b[A\n",
            " 15% 12/82 [00:02<00:12,  5.49it/s]\u001b[A\n",
            " 16% 13/82 [00:02<00:12,  5.49it/s]\u001b[A\n",
            " 17% 14/82 [00:02<00:12,  5.50it/s]\u001b[A\n",
            " 18% 15/82 [00:02<00:12,  5.50it/s]\u001b[A\n",
            " 20% 16/82 [00:02<00:11,  5.50it/s]\u001b[A\n",
            " 21% 17/82 [00:02<00:11,  5.48it/s]\u001b[A\n",
            " 22% 18/82 [00:03<00:11,  5.48it/s]\u001b[A\n",
            " 23% 19/82 [00:03<00:11,  5.48it/s]\u001b[A\n",
            " 24% 20/82 [00:03<00:11,  5.47it/s]\u001b[A\n",
            " 26% 21/82 [00:03<00:11,  5.45it/s]\u001b[A\n",
            " 27% 22/82 [00:03<00:11,  5.45it/s]\u001b[A\n",
            " 28% 23/82 [00:04<00:10,  5.45it/s]\u001b[A\n",
            " 29% 24/82 [00:04<00:10,  5.47it/s]\u001b[A\n",
            " 30% 25/82 [00:04<00:10,  5.47it/s]\u001b[A\n",
            " 32% 26/82 [00:04<00:10,  5.47it/s]\u001b[A\n",
            " 33% 27/82 [00:04<00:10,  5.48it/s]\u001b[A\n",
            " 34% 28/82 [00:04<00:09,  5.49it/s]\u001b[A\n",
            " 35% 29/82 [00:05<00:09,  5.49it/s]\u001b[A\n",
            " 37% 30/82 [00:05<00:09,  5.49it/s]\u001b[A\n",
            " 38% 31/82 [00:05<00:09,  5.49it/s]\u001b[A\n",
            " 39% 32/82 [00:05<00:09,  5.50it/s]\u001b[A\n",
            " 40% 33/82 [00:05<00:08,  5.49it/s]\u001b[A\n",
            " 41% 34/82 [00:06<00:08,  5.48it/s]\u001b[A\n",
            " 43% 35/82 [00:06<00:08,  5.50it/s]\u001b[A\n",
            " 44% 36/82 [00:06<00:08,  5.50it/s]\u001b[A\n",
            " 45% 37/82 [00:06<00:08,  5.50it/s]\u001b[A\n",
            " 46% 38/82 [00:06<00:08,  5.50it/s]\u001b[A\n",
            " 48% 39/82 [00:06<00:07,  5.49it/s]\u001b[A\n",
            " 49% 40/82 [00:07<00:07,  5.49it/s]\u001b[A\n",
            " 50% 41/82 [00:07<00:07,  5.50it/s]\u001b[A\n",
            " 51% 42/82 [00:07<00:07,  5.49it/s]\u001b[A\n",
            " 52% 43/82 [00:07<00:07,  5.49it/s]\u001b[A\n",
            " 54% 44/82 [00:07<00:06,  5.49it/s]\u001b[A\n",
            " 55% 45/82 [00:08<00:06,  5.49it/s]\u001b[A\n",
            " 56% 46/82 [00:08<00:06,  5.49it/s]\u001b[A\n",
            " 57% 47/82 [00:08<00:06,  5.49it/s]\u001b[A\n",
            " 59% 48/82 [00:08<00:06,  5.48it/s]\u001b[A\n",
            " 60% 49/82 [00:08<00:06,  5.49it/s]\u001b[A\n",
            " 61% 50/82 [00:08<00:05,  5.48it/s]\u001b[A\n",
            " 62% 51/82 [00:09<00:05,  5.48it/s]\u001b[A\n",
            " 63% 52/82 [00:09<00:05,  5.48it/s]\u001b[A\n",
            " 65% 53/82 [00:09<00:05,  5.49it/s]\u001b[A\n",
            " 66% 54/82 [00:09<00:05,  5.49it/s]\u001b[A\n",
            " 67% 55/82 [00:09<00:04,  5.49it/s]\u001b[A\n",
            " 68% 56/82 [00:10<00:04,  5.49it/s]\u001b[A\n",
            " 70% 57/82 [00:10<00:04,  5.50it/s]\u001b[A\n",
            " 71% 58/82 [00:10<00:04,  5.49it/s]\u001b[A\n",
            " 72% 59/82 [00:10<00:04,  5.48it/s]\u001b[A\n",
            " 73% 60/82 [00:10<00:04,  5.48it/s]\u001b[A\n",
            " 74% 61/82 [00:10<00:03,  5.46it/s]\u001b[A\n",
            " 76% 62/82 [00:11<00:03,  5.46it/s]\u001b[A\n",
            " 77% 63/82 [00:11<00:03,  5.20it/s]\u001b[A\n",
            " 78% 64/82 [00:11<00:03,  5.06it/s]\u001b[A\n",
            " 79% 65/82 [00:11<00:03,  4.97it/s]\u001b[A\n",
            " 80% 66/82 [00:12<00:03,  4.90it/s]\u001b[A\n",
            " 82% 67/82 [00:12<00:03,  4.86it/s]\u001b[A\n",
            " 83% 68/82 [00:12<00:02,  4.82it/s]\u001b[A\n",
            " 84% 69/82 [00:12<00:02,  4.80it/s]\u001b[A\n",
            " 85% 70/82 [00:12<00:02,  4.79it/s]\u001b[A\n",
            " 87% 71/82 [00:13<00:02,  4.75it/s]\u001b[A\n",
            " 88% 72/82 [00:13<00:02,  4.75it/s]\u001b[A\n",
            " 89% 73/82 [00:13<00:01,  4.75it/s]\u001b[A\n",
            " 90% 74/82 [00:13<00:01,  4.76it/s]\u001b[A\n",
            " 91% 75/82 [00:13<00:01,  4.75it/s]\u001b[A\n",
            " 93% 76/82 [00:14<00:01,  4.76it/s]\u001b[A\n",
            " 94% 77/82 [00:14<00:01,  4.75it/s]\u001b[A\n",
            " 95% 78/82 [00:14<00:00,  4.75it/s]\u001b[A\n",
            " 96% 79/82 [00:14<00:00,  4.76it/s]\u001b[A\n",
            " 98% 80/82 [00:14<00:00,  4.75it/s]\u001b[A\n",
            " 99% 81/82 [00:15<00:00,  4.72it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.05012623220682144, 'eval_precision': 0.9904176315885007, 'eval_recall': 0.9902105767428298, 'eval_f1': 0.9902859626693475, 'eval_accuracy': 0.9902105767428298, 'eval_runtime': 16.4468, 'eval_samples_per_second': 79.712, 'eval_steps_per_second': 4.986, 'epoch': 4.0}\n",
            " 67% 668/1002 [16:23<06:10,  1.11s/it]\n",
            "100% 82/82 [00:16<00:00,  4.71it/s]\u001b[A\n",
            "                                   \u001b[A/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            " 83% 835/1002 [20:10<03:03,  1.10s/it]\n",
            "  0% 0/82 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/82 [00:00<00:07, 10.97it/s]\u001b[A\n",
            "  5% 4/82 [00:00<00:11,  6.89it/s]\u001b[A\n",
            "  6% 5/82 [00:00<00:12,  6.36it/s]\u001b[A\n",
            "  7% 6/82 [00:00<00:12,  6.08it/s]\u001b[A\n",
            "  9% 7/82 [00:01<00:12,  5.89it/s]\u001b[A\n",
            " 10% 8/82 [00:01<00:12,  5.74it/s]\u001b[A\n",
            " 11% 9/82 [00:01<00:12,  5.67it/s]\u001b[A\n",
            " 12% 10/82 [00:01<00:12,  5.60it/s]\u001b[A\n",
            " 13% 11/82 [00:01<00:12,  5.56it/s]\u001b[A\n",
            " 15% 12/82 [00:02<00:12,  5.54it/s]\u001b[A\n",
            " 16% 13/82 [00:02<00:12,  5.53it/s]\u001b[A\n",
            " 17% 14/82 [00:02<00:12,  5.51it/s]\u001b[A\n",
            " 18% 15/82 [00:02<00:12,  5.51it/s]\u001b[A\n",
            " 20% 16/82 [00:02<00:12,  5.49it/s]\u001b[A\n",
            " 21% 17/82 [00:02<00:11,  5.50it/s]\u001b[A\n",
            " 22% 18/82 [00:03<00:11,  5.46it/s]\u001b[A\n",
            " 23% 19/82 [00:03<00:11,  5.45it/s]\u001b[A\n",
            " 24% 20/82 [00:03<00:11,  5.44it/s]\u001b[A\n",
            " 26% 21/82 [00:03<00:11,  5.43it/s]\u001b[A\n",
            " 27% 22/82 [00:03<00:11,  5.42it/s]\u001b[A\n",
            " 28% 23/82 [00:04<00:10,  5.40it/s]\u001b[A\n",
            " 29% 24/82 [00:04<00:10,  5.41it/s]\u001b[A\n",
            " 30% 25/82 [00:04<00:10,  5.44it/s]\u001b[A\n",
            " 32% 26/82 [00:04<00:10,  5.45it/s]\u001b[A\n",
            " 33% 27/82 [00:04<00:10,  5.46it/s]\u001b[A\n",
            " 34% 28/82 [00:04<00:09,  5.46it/s]\u001b[A\n",
            " 35% 29/82 [00:05<00:09,  5.45it/s]\u001b[A\n",
            " 37% 30/82 [00:05<00:09,  5.46it/s]\u001b[A\n",
            " 38% 31/82 [00:05<00:09,  5.46it/s]\u001b[A\n",
            " 39% 32/82 [00:05<00:09,  5.48it/s]\u001b[A\n",
            " 40% 33/82 [00:05<00:08,  5.48it/s]\u001b[A\n",
            " 41% 34/82 [00:06<00:08,  5.49it/s]\u001b[A\n",
            " 43% 35/82 [00:06<00:08,  5.49it/s]\u001b[A\n",
            " 44% 36/82 [00:06<00:08,  5.49it/s]\u001b[A\n",
            " 45% 37/82 [00:06<00:08,  5.49it/s]\u001b[A\n",
            " 46% 38/82 [00:06<00:08,  5.49it/s]\u001b[A\n",
            " 48% 39/82 [00:06<00:07,  5.47it/s]\u001b[A\n",
            " 49% 40/82 [00:07<00:07,  5.46it/s]\u001b[A\n",
            " 50% 41/82 [00:07<00:07,  5.46it/s]\u001b[A\n",
            " 51% 42/82 [00:07<00:07,  5.47it/s]\u001b[A\n",
            " 52% 43/82 [00:07<00:07,  5.48it/s]\u001b[A\n",
            " 54% 44/82 [00:07<00:06,  5.48it/s]\u001b[A\n",
            " 55% 45/82 [00:08<00:06,  5.50it/s]\u001b[A\n",
            " 56% 46/82 [00:08<00:06,  5.51it/s]\u001b[A\n",
            " 57% 47/82 [00:08<00:06,  5.49it/s]\u001b[A\n",
            " 59% 48/82 [00:08<00:06,  5.50it/s]\u001b[A\n",
            " 60% 49/82 [00:08<00:05,  5.51it/s]\u001b[A\n",
            " 61% 50/82 [00:08<00:05,  5.51it/s]\u001b[A\n",
            " 62% 51/82 [00:09<00:05,  5.52it/s]\u001b[A\n",
            " 63% 52/82 [00:09<00:05,  5.51it/s]\u001b[A\n",
            " 65% 53/82 [00:09<00:05,  5.49it/s]\u001b[A\n",
            " 66% 54/82 [00:09<00:05,  5.49it/s]\u001b[A\n",
            " 67% 55/82 [00:09<00:04,  5.50it/s]\u001b[A\n",
            " 68% 56/82 [00:10<00:04,  5.51it/s]\u001b[A\n",
            " 70% 57/82 [00:10<00:04,  5.50it/s]\u001b[A\n",
            " 71% 58/82 [00:10<00:04,  5.49it/s]\u001b[A\n",
            " 72% 59/82 [00:10<00:04,  5.49it/s]\u001b[A\n",
            " 73% 60/82 [00:10<00:04,  5.49it/s]\u001b[A\n",
            " 74% 61/82 [00:10<00:03,  5.51it/s]\u001b[A\n",
            " 76% 62/82 [00:11<00:03,  5.49it/s]\u001b[A\n",
            " 77% 63/82 [00:11<00:03,  5.28it/s]\u001b[A\n",
            " 78% 64/82 [00:11<00:03,  5.14it/s]\u001b[A\n",
            " 79% 65/82 [00:11<00:03,  5.05it/s]\u001b[A\n",
            " 80% 66/82 [00:11<00:03,  4.98it/s]\u001b[A\n",
            " 82% 67/82 [00:12<00:03,  4.93it/s]\u001b[A\n",
            " 83% 68/82 [00:12<00:02,  4.86it/s]\u001b[A\n",
            " 84% 69/82 [00:12<00:02,  4.85it/s]\u001b[A\n",
            " 85% 70/82 [00:12<00:02,  4.84it/s]\u001b[A\n",
            " 87% 71/82 [00:13<00:02,  4.84it/s]\u001b[A\n",
            " 88% 72/82 [00:13<00:02,  4.83it/s]\u001b[A\n",
            " 89% 73/82 [00:13<00:01,  4.84it/s]\u001b[A\n",
            " 90% 74/82 [00:13<00:01,  4.84it/s]\u001b[A\n",
            " 91% 75/82 [00:13<00:01,  4.85it/s]\u001b[A\n",
            " 93% 76/82 [00:14<00:01,  4.84it/s]\u001b[A\n",
            " 94% 77/82 [00:14<00:01,  4.83it/s]\u001b[A\n",
            " 95% 78/82 [00:14<00:00,  4.83it/s]\u001b[A\n",
            " 96% 79/82 [00:14<00:00,  4.83it/s]\u001b[A\n",
            " 98% 80/82 [00:14<00:00,  4.83it/s]\u001b[A\n",
            " 99% 81/82 [00:15<00:00,  4.82it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.05093172937631607, 'eval_precision': 0.9900268159249744, 'eval_recall': 0.9898564912207619, 'eval_f1': 0.9899204522953875, 'eval_accuracy': 0.9898564912207619, 'eval_runtime': 15.9269, 'eval_samples_per_second': 82.314, 'eval_steps_per_second': 5.149, 'epoch': 5.0}\n",
            " 83% 835/1002 [20:26<03:03,  1.10s/it]\n",
            "100% 82/82 [00:15<00:00,  4.80it/s]\u001b[A\n",
            "                                   \u001b[A/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0163, 'learning_rate': 3.992015968063872e-08, 'epoch': 5.99}\n",
            "100% 1000/1002 [24:12<00:02,  1.38s/it]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "100% 1002/1002 [24:19<00:00,  2.29s/it]\n",
            "  0% 0/82 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 2/82 [00:00<00:07, 11.28it/s]\u001b[A\n",
            "  5% 4/82 [00:00<00:11,  6.84it/s]\u001b[A\n",
            "  6% 5/82 [00:00<00:12,  6.34it/s]\u001b[A\n",
            "  7% 6/82 [00:00<00:12,  6.10it/s]\u001b[A\n",
            "  9% 7/82 [00:01<00:12,  5.92it/s]\u001b[A\n",
            " 10% 8/82 [00:01<00:12,  5.75it/s]\u001b[A\n",
            " 11% 9/82 [00:01<00:12,  5.64it/s]\u001b[A\n",
            " 12% 10/82 [00:01<00:12,  5.62it/s]\u001b[A\n",
            " 13% 11/82 [00:01<00:12,  5.58it/s]\u001b[A\n",
            " 15% 12/82 [00:02<00:12,  5.56it/s]\u001b[A\n",
            " 16% 13/82 [00:02<00:12,  5.55it/s]\u001b[A\n",
            " 17% 14/82 [00:02<00:12,  5.49it/s]\u001b[A\n",
            " 18% 15/82 [00:02<00:12,  5.49it/s]\u001b[A\n",
            " 20% 16/82 [00:02<00:11,  5.51it/s]\u001b[A\n",
            " 21% 17/82 [00:02<00:11,  5.52it/s]\u001b[A\n",
            " 22% 18/82 [00:03<00:11,  5.52it/s]\u001b[A\n",
            " 23% 19/82 [00:03<00:11,  5.50it/s]\u001b[A\n",
            " 24% 20/82 [00:03<00:11,  5.47it/s]\u001b[A\n",
            " 26% 21/82 [00:03<00:11,  5.49it/s]\u001b[A\n",
            " 27% 22/82 [00:03<00:10,  5.49it/s]\u001b[A\n",
            " 28% 23/82 [00:04<00:10,  5.48it/s]\u001b[A\n",
            " 29% 24/82 [00:04<00:10,  5.49it/s]\u001b[A\n",
            " 30% 25/82 [00:04<00:10,  5.47it/s]\u001b[A\n",
            " 32% 26/82 [00:04<00:10,  5.48it/s]\u001b[A\n",
            " 33% 27/82 [00:04<00:10,  5.49it/s]\u001b[A\n",
            " 34% 28/82 [00:04<00:09,  5.49it/s]\u001b[A\n",
            " 35% 29/82 [00:05<00:09,  5.50it/s]\u001b[A\n",
            " 37% 30/82 [00:05<00:09,  5.49it/s]\u001b[A\n",
            " 38% 31/82 [00:05<00:09,  5.46it/s]\u001b[A\n",
            " 39% 32/82 [00:05<00:09,  5.39it/s]\u001b[A\n",
            " 40% 33/82 [00:05<00:09,  5.42it/s]\u001b[A\n",
            " 41% 34/82 [00:06<00:08,  5.33it/s]\u001b[A\n",
            " 43% 35/82 [00:06<00:08,  5.30it/s]\u001b[A\n",
            " 44% 36/82 [00:06<00:08,  5.24it/s]\u001b[A\n",
            " 45% 37/82 [00:06<00:08,  5.29it/s]\u001b[A\n",
            " 46% 38/82 [00:06<00:08,  5.24it/s]\u001b[A\n",
            " 48% 39/82 [00:07<00:08,  5.24it/s]\u001b[A\n",
            " 49% 40/82 [00:07<00:08,  5.23it/s]\u001b[A\n",
            " 50% 41/82 [00:07<00:07,  5.22it/s]\u001b[A\n",
            " 51% 42/82 [00:07<00:07,  5.15it/s]\u001b[A\n",
            " 52% 43/82 [00:07<00:07,  5.19it/s]\u001b[A\n",
            " 54% 44/82 [00:07<00:07,  5.22it/s]\u001b[A\n",
            " 55% 45/82 [00:08<00:06,  5.29it/s]\u001b[A\n",
            " 56% 46/82 [00:08<00:06,  5.30it/s]\u001b[A\n",
            " 57% 47/82 [00:08<00:06,  5.34it/s]\u001b[A\n",
            " 59% 48/82 [00:08<00:06,  5.38it/s]\u001b[A\n",
            " 60% 49/82 [00:08<00:06,  5.40it/s]\u001b[A\n",
            " 61% 50/82 [00:09<00:05,  5.40it/s]\u001b[A\n",
            " 62% 51/82 [00:09<00:05,  5.38it/s]\u001b[A\n",
            " 63% 52/82 [00:09<00:05,  5.38it/s]\u001b[A\n",
            " 65% 53/82 [00:09<00:05,  5.37it/s]\u001b[A\n",
            " 66% 54/82 [00:09<00:05,  5.38it/s]\u001b[A\n",
            " 67% 55/82 [00:10<00:05,  5.38it/s]\u001b[A\n",
            " 68% 56/82 [00:10<00:04,  5.35it/s]\u001b[A\n",
            " 70% 57/82 [00:10<00:04,  5.33it/s]\u001b[A\n",
            " 71% 58/82 [00:10<00:04,  5.33it/s]\u001b[A\n",
            " 72% 59/82 [00:10<00:04,  5.33it/s]\u001b[A\n",
            " 73% 60/82 [00:10<00:04,  5.34it/s]\u001b[A\n",
            " 74% 61/82 [00:11<00:03,  5.35it/s]\u001b[A\n",
            " 76% 62/82 [00:11<00:03,  5.37it/s]\u001b[A\n",
            " 77% 63/82 [00:11<00:03,  5.15it/s]\u001b[A\n",
            " 78% 64/82 [00:11<00:03,  5.02it/s]\u001b[A\n",
            " 79% 65/82 [00:11<00:03,  4.89it/s]\u001b[A\n",
            " 80% 66/82 [00:12<00:03,  4.84it/s]\u001b[A\n",
            " 82% 67/82 [00:12<00:03,  4.79it/s]\u001b[A\n",
            " 83% 68/82 [00:12<00:02,  4.80it/s]\u001b[A\n",
            " 84% 69/82 [00:12<00:02,  4.80it/s]\u001b[A\n",
            " 85% 70/82 [00:13<00:02,  4.79it/s]\u001b[A\n",
            " 87% 71/82 [00:13<00:02,  4.80it/s]\u001b[A\n",
            " 88% 72/82 [00:13<00:02,  4.81it/s]\u001b[A\n",
            " 89% 73/82 [00:13<00:01,  4.79it/s]\u001b[A\n",
            " 90% 74/82 [00:13<00:01,  4.77it/s]\u001b[A\n",
            " 91% 75/82 [00:14<00:01,  4.80it/s]\u001b[A\n",
            " 93% 76/82 [00:14<00:01,  4.80it/s]\u001b[A\n",
            " 94% 77/82 [00:14<00:01,  4.79it/s]\u001b[A\n",
            " 95% 78/82 [00:14<00:00,  4.79it/s]\u001b[A\n",
            " 96% 79/82 [00:14<00:00,  4.77it/s]\u001b[A\n",
            " 98% 80/82 [00:15<00:00,  4.79it/s]\u001b[A\n",
            " 99% 81/82 [00:15<00:00,  4.80it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.0514533594250679, 'eval_precision': 0.9900342255378123, 'eval_recall': 0.9898564912207619, 'eval_f1': 0.9899274649058405, 'eval_accuracy': 0.9898564912207619, 'eval_runtime': 16.1328, 'eval_samples_per_second': 81.263, 'eval_steps_per_second': 5.083, 'epoch': 6.0}\n",
            "100% 1002/1002 [24:36<00:00,  2.29s/it]\n",
            "100% 82/82 [00:15<00:00,  4.77it/s]\u001b[A\n",
            "{'train_runtime': 1476.1221, 'train_samples_per_second': 10.816, 'train_steps_per_second': 0.679, 'train_loss': 0.026368275777382884, 'epoch': 6.0}\n",
            "100% 1002/1002 [24:36<00:00,  1.47s/it]\n",
            "model saved succefully to /content/drive/MyDrive/RDI/RDI-NER/weigths/D:2023-07-11H-12:56:52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python infer.py \"إمارة أبوظبي هي إحدى إمارات دولة- الإمارات العربية المتحدة السبع ؟\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyTEPU3ivrvf",
        "outputId": "9df9d0dd-f32e-45c9-d352-d30c5c524371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-11 11:37:18.234279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "words   | labels \n",
            "-------\t--------\n",
            "إمارة\tO\n",
            "أبوظبي\tB-LOC\n",
            "هي\tO\n",
            "إحدى\tO\n",
            "إمارات\tO\n",
            "دولة\tO\n",
            "الإمارات\tB-LOC\n",
            "العربية\tI-LOC\n",
            "المتحدة\tI-LOC\n",
            "السبع\tO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py $model_path $tokenizer_path \"For Fine_tuned model\" #change to new model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBsqlfXSm44k",
        "outputId": "628610aa-85e3-43dc-f055-8bebbdfb933a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-11 11:50:06.610491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "\n",
            "Classification report for For Fine_tuned model \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.90      0.95      0.92       665\n",
            "      B-MISC       0.75      0.63      0.68       235\n",
            "       B-ORG       0.78      0.74      0.76       450\n",
            "      B-PERS       0.88      0.86      0.87       857\n",
            "       I-LOC       0.82      0.81      0.81        83\n",
            "      I-MISC       0.75      0.37      0.49       163\n",
            "       I-ORG       0.77      0.69      0.73       275\n",
            "      I-PERS       0.90      0.88      0.89       638\n",
            "           O       0.98      0.99      0.99     19093\n",
            "\n",
            "    accuracy                           0.97     22459\n",
            "   macro avg       0.84      0.77      0.79     22459\n",
            "weighted avg       0.96      0.97      0.96     22459\n",
            "\n",
            "\n",
            "Confussion matrix for  For Fine_tuned model \n",
            "[[  632     1     7     3     0     0     3     1    18]\n",
            " [    6   148    12     4     0     2     0     3    60]\n",
            " [   22     5   333    19     4     0     3     0    64]\n",
            " [   12    12    17   735     0     1     0    36    44]\n",
            " [    5     1     2     0    67     1     0     0     7]\n",
            " [    8    10     2     1     4    60    18     2    58]\n",
            " [    3     0    16     3     2     1   190     9    51]\n",
            " [    3     2     0    41     1     5     5   561    20]\n",
            " [   11    19    38    29     4    10    27     8 18947]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py 'CAMeL-Lab/bert-base-arabic-camelbert-mix-ner' 'CAMeL-Lab/bert-base-arabic-camelbert-mix-ner' 'For Baseline'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33AY1_wV-SVY",
        "outputId": "56418c97-3b55-4457-aa52-004d4598d70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-11 11:46:43.651604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "\n",
            "Classification report for For Baseline \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.88      0.94      0.91       665\n",
            "      B-MISC       0.78      0.58      0.66       235\n",
            "       B-ORG       0.80      0.73      0.76       450\n",
            "      B-PERS       0.87      0.85      0.86       857\n",
            "       I-LOC       0.83      0.83      0.83        83\n",
            "      I-MISC       0.79      0.34      0.47       163\n",
            "       I-ORG       0.78      0.69      0.73       275\n",
            "      I-PERS       0.89      0.89      0.89       638\n",
            "           O       0.98      0.99      0.99     19093\n",
            "\n",
            "    accuracy                           0.96     22459\n",
            "   macro avg       0.84      0.76      0.79     22459\n",
            "weighted avg       0.96      0.96      0.96     22459\n",
            "\n",
            "\n",
            "Confussion matrix for  For Baseline \n",
            "[[  626     1     7     4     0     0     3     1    23]\n",
            " [    9   136    14     5     0     1     0     3    67]\n",
            " [   23     5   327    19     4     0     8     1    63]\n",
            " [   11     7    18   730     0     0     2    43    46]\n",
            " [    5     0     0     0    69     0     0     0     9]\n",
            " [   11     6     0     1     4    55    17     2    67]\n",
            " [    4     0    10     6     2     1   190     9    53]\n",
            " [    2     0     0    37     1     5     2   571    20]\n",
            " [   17    20    32    40     3     8    21    10 18942]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MpFtypBdYxS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-l9eLTjQYxQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T9TUUT3JYxNi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
